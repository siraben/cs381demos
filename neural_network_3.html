<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Neural Networks Part 3: Backpropagation & Training</title>

  <!-- Social Media Preview Tags -->
  <meta property="og:title" content="Neural Networks Part 3: Backpropagation & Training Demo">
  <meta property="og:description" content="Visualize training a simple neural network using backpropagation on various 2D datasets.">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Neural Networks Part 3: Backpropagation & Training Demo">
  <meta name="twitter:description" content="Visualize training a simple neural network using backpropagation on various 2D datasets.">

  <!-- Plotly for any visualizations -->
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

  <!-- MathJax for equation rendering -->
  <script>
    window.MathJax = {
      tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" async></script>

  <!-- Link shared CSS -->
  <link rel="stylesheet" href="styles.css">
  <style>
    /* Specific styles from Part 2 (SVG Network) */
    .network-visualization svg {
        display: block;
        margin: 0 auto;
        max-width: 500px; /* Limit width */
    }
    .neuron-circle {
        stroke: #333;
        stroke-width: 1px;
        transition: fill 0.1s ease-in-out; /* Smooth activation color change */
    }
    .input-node-circle { fill: #90ee90; }
    .hidden-node-circle { fill: #add8e6; }
    .output-node-circle { fill: #ffcccb; }
    .neuron-text {
        font-family: sans-serif; font-size: 10px; text-anchor: middle;
        dominant-baseline: middle; fill: #000; pointer-events: none;
    }
    .connection-line {
        stroke: #888; stroke-width: 1;
        transition: stroke-width 0.1s ease-in-out; /* Highlight weights */
    }
    .weight-text {
        font-family: sans-serif; font-size: 8px; text-anchor: middle;
        fill: #555; pointer-events: none;
    }
    .layer-label {
        font-family: sans-serif; font-size: 12px; font-weight: bold;
        text-anchor: middle;
    }
    /* Additional styles for training */
    #lossPlotContainer { margin-top: 20px; }
    #status {
        margin-top: 10px; font-style: italic; text-align: center;
        min-height: 1.2em; /* Prevent layout shift */
    }
    .plot-container { margin-bottom: 20px; }
    .button-group button { margin: 5px; } /* Spacing for buttons */
  </style>
</head>
<body>
<div class="container">
  <h1>Neural Networks Part 3: Backpropagation & Training</h1>
  <p>Training a simple neural network to classify 2D data using the backpropagation algorithm.</p>

  <div class="controls">
        <div class="control-box">
            <label for="numPointsSlider">Points Per Class:</label><br/>
            <input type="range" id="numPointsSlider" min="20" max="200" step="10" value="50" /><br/>
            <span id="numPointsValue">50</span>
        </div>
        <div class="control-box">
            <label for="datasetSelect">Dataset:</label><br/>
            <select id="datasetSelect">
                <option value="circles">Concentric Circles</option>
                <option value="xor">XOR Pattern</option>
                <option value="moons">Two Moons</option>
                <option value="linear">Linearly Separable</option>
                <option value="spiral">Spiral</option>
                <option value="gaussians">Gaussian Blobs</option>
            </select>
        </div>
        <div class="control-box">
            <label for="lrSlider">Learning Rate (α):</label><br/>
            <input type="range" id="lrSlider" min="-3" max="0" step="0.1" value="-1" /> <!-- Log scale: 10^-3 to 10^0 -->
            <span>α = 10^</span><span id="lrValue">-1.0</span>
        </div>
         <div class="control-box">
            <label for="updateSpeedSlider">Update Speed:</label><br/>
            <input type="range" id="updateSpeedSlider" min="1" max="50" step="1" value="10" /><br/>
            <span id="updateSpeedValue">10</span><span> steps/frame</span>
        </div>
       <div class="control-box">
            <label for="activationSelect">Hidden Activation:</label><br/>
            <select id="activationSelect">
                <option value="sigmoid" selected>Sigmoid</option>
                <option value="tanh">Tanh</option>
                <option value="relu">ReLU</option>
            </select>
        </div>
       <div class="control-box button-group">
          <button id="startBtn">Start Training</button>
          <button id="stopBtn" disabled>Stop Training</button>
          <button id="stepBtn">Step Once</button>
          <button id="resetWeightsBtn">Reset Weights</button>
          <button id="generateDataBtn">Generate New Data</button>
        </div>
  </div>

  <div id="status">Status: Ready</div>

  <div class="network-visualization">
     <svg id="networkSvg" width="500" height="250"></svg>
     <!-- SVG generated by JS -->
  </div>

  <div id="decisionBoundaryPlot" class="plot-container" style="height: 500px;">
      <!-- Plotly plot showing data and decision boundary -->
  </div>

  <div id="lossPlotContainer" class="plot-container" style="height: 300px;">
      <!-- Plotly plot showing loss over epochs/steps -->
  </div>


  <div id="explanation">
    <h3>Training the Network: Backpropagation</h3>
    <p>
      Parts 1 and 2 showed how a network with fixed weights makes predictions (forward propagation). But how does the network <i>learn</i> the correct weights and biases? This is done through <strong>training</strong>, most commonly using the <strong>backpropagation</strong> algorithm coupled with gradient descent.
    </p>
    <p>
      The process involves repeating these steps for many training examples (stochastic gradient descent):
      <ol>
        <li><strong>Forward Pass:</strong> Feed an input (e.g., \(\mathbf{x}=[x_1, x_2]\)) through the network to get the output prediction \(\hat{y}\). Store intermediate values (activations \(a\) and weighted sums \(z\)).</li>
        <li><strong>Calculate Loss:</strong> Compare the prediction \(\hat{y}\) to the true target label \(y\) (0 or 1) using Mean Squared Error (MSE):
        \[ L = \frac{1}{2} (y - \hat{y})^2 \]
        </li>
        <li><strong>Backward Pass (Backpropagation):</strong> Calculate the gradient of the loss with respect to each weight and bias. This uses the chain rule, propagating the error backward from the output layer:
            <ul>
                <li>Output layer error delta: \( \delta_o = (\hat{y} - y) \cdot g'(z_o) \) where \(g'\) is the sigmoid derivative.</li>
                <li>Hidden layer error delta(s): \( \delta_{h_j} = (\sum_k \delta_o w_{kj}) \cdot g'(z_{h_j}) \) (Sum over output neurons k, only one here)</li>
                <li>Output layer weight gradients: \( \frac{\partial L}{\partial w_{oj}} = \delta_o \cdot a_{h_j} \)</li>
                <li>Output layer bias gradient: \( \frac{\partial L}{\partial b_{o}} = \delta_o \)</li>
                <li>Hidden layer weight gradients: \( \frac{\partial L}{\partial w_{ji}} = \delta_{h_j} \cdot x_i \)</li>
                <li>Hidden layer bias gradients: \( \frac{\partial L}{\partial b_{h_j}} = \delta_{h_j} \)</li>
            </ul>
        </li>
        <li><strong>Update Weights:</strong> Adjust weights and biases opposite to their gradients, scaled by learning rate \(\alpha\):
        \[ w_{new} = w_{old} - \alpha \frac{\partial L}{\partial w_{old}} \quad , \quad b_{new} = b_{old} - \alpha \frac{\partial L}{\partial b_{old}} \]
        </li>
      </ol>
    </p>
    <p>
        This demo lets you choose a dataset, adjust the learning rate, and observe the network learning the classification boundary shown in the plot below the network diagram. The final plot shows the training loss decreasing over time.
    </p>
  </div>

  <div class="back-link">
    <a href="index.html">&larr; Back to Homepage</a>
  </div>

  <div class="footer">
    <em>Part 3 of a Neural Networks series. Training with Backpropagation.</em>
  </div>
</div>

<!-- Include shared JS utilities -->
<script src="plotUtils.js"></script>

<script>
// --- Constants & Global State ---
const svgNS = "http://www.w3.org/2000/svg";
const PLOT_RANGE = [-6, 6]; // Range for dataset generation and boundary plot

// Network Structure (2 inputs, 3 hidden neurons, 1 output neuron)
const NUM_INPUTS = 2;
const NUM_HIDDEN = 3;
const NUM_OUTPUTS = 1; // Single output neuron for binary classification

let weights_h, biases_h, weights_o, bias_o; // Network parameters (will be initialized)
let dataset = { data: [], labels: [] };      // Current training data
let rawData = { class0: {x:[],y:[]}, class1:{x:[],y:[]}}; // For plotting
let lossHistory = [];
let stepCount = 0;
let isTraining = false;
let animationFrameId = null;

// --- DOM Elements ---
const numPointsSlider = document.getElementById('numPointsSlider');
const numPointsValue = document.getElementById('numPointsValue');
const datasetSelect = document.getElementById('datasetSelect');
const lrSlider = document.getElementById('lrSlider');
const lrValue = document.getElementById('lrValue');
const updateSpeedSlider = document.getElementById('updateSpeedSlider');
const updateSpeedValue = document.getElementById('updateSpeedValue');
const activationSelect = document.getElementById('activationSelect');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const stepBtn = document.getElementById('stepBtn');
const resetWeightsBtn = document.getElementById('resetWeightsBtn');
const generateDataBtn = document.getElementById('generateDataBtn');
const statusDiv = document.getElementById('status');
const networkSvg = document.getElementById('networkSvg');
const decisionBoundaryPlotDiv = document.getElementById('decisionBoundaryPlot');
const lossPlotDiv = document.getElementById('lossPlotContainer');

// --- Network & Math Functions ---
const activations = {
    sigmoid: {
        func: z => 1 / (1 + Math.exp(-z)),
        derivative: y => y * (1 - y) // Takes sigmoid output y
    },
    tanh: {
        func: z => Math.tanh(z),
        derivative: y => 1 - y * y // Takes tanh output y
    },
    relu: {
        func: z => Math.max(0, z),
        derivative: y => (y > 0 ? 1 : 0) // Takes relu output y
    }
};
let currentActivation = activations.sigmoid; // Default

const mseLoss = (y_true, y_pred) => 0.5 * (y_pred - y_true) ** 2;
const mseLossDerivative = (y_true, y_pred) => y_pred - y_true;

// He weight initialization (good for ReLU, okay for sigmoid too)
function initializeWeights() {
    weights_h = Array(NUM_HIDDEN).fill(0).map(() =>
        Array(NUM_INPUTS).fill(0).map(() => (Math.random() - 0.5) * Math.sqrt(2 / NUM_INPUTS))
    );
    biases_h = Array(NUM_HIDDEN).fill(0); // Initialize biases to zero

    weights_o = Array(NUM_OUTPUTS).fill(0).map(() =>
        Array(NUM_HIDDEN).fill(0).map(() => (Math.random() - 0.5) * Math.sqrt(2 / NUM_HIDDEN))
    );
    bias_o = Array(NUM_OUTPUTS).fill(0); // Initialize biases to zero

    stepCount = 0;
    lossHistory = [];
    console.log("Weights initialized.");
}

function forwardPass(inputs) {
    // Hidden Layer
    const z_h = Array(NUM_HIDDEN).fill(0);
    const a_h = Array(NUM_HIDDEN).fill(0);
    for (let j = 0; j < NUM_HIDDEN; j++) {
        z_h[j] = biases_h[j]; // Start with bias
        for (let i = 0; i < NUM_INPUTS; i++) {
            z_h[j] += inputs[i] * weights_h[j][i];
        }
        a_h[j] = currentActivation.func(z_h[j]); // Use selected activation
    }

    // Output Layer (remains sigmoid)
    const z_o = Array(NUM_OUTPUTS).fill(0);
    const a_o = Array(NUM_OUTPUTS).fill(0);
    for (let k = 0; k < NUM_OUTPUTS; k++) {
        z_o[k] = bias_o[k]; // Start with bias
        for (let j = 0; j < NUM_HIDDEN; j++) {
            z_o[k] += a_h[j] * weights_o[k][j];
        }
        a_o[k] = activations.sigmoid.func(z_o[k]); // Output always sigmoid
    }

    return { z_h, a_h, z_o, a_o };
}

function backpropagation(inputs, target, forwardResult) {
    const { z_h, a_h, z_o, a_o } = forwardResult;
    const y_pred = a_o[0];
    const y_true = target;

    // Gradients for weights/biases
    const grad_weights_o = Array(NUM_OUTPUTS).fill(0).map(() => Array(NUM_HIDDEN).fill(0));
    const grad_bias_o = Array(NUM_OUTPUTS).fill(0);
    const grad_weights_h = Array(NUM_HIDDEN).fill(0).map(() => Array(NUM_INPUTS).fill(0));
    const grad_biases_h = Array(NUM_HIDDEN).fill(0);

    // Output Layer Gradients (using sigmoid derivative)
    const delta_o = Array(NUM_OUTPUTS).fill(0);
    for (let k = 0; k < NUM_OUTPUTS; k++) {
        const error_term = mseLossDerivative(y_true, y_pred);
        const activation_derivative = activations.sigmoid.derivative(a_o[k]); // Output derivative
        delta_o[k] = error_term * activation_derivative;
        grad_bias_o[k] = delta_o[k];
        for (let j = 0; j < NUM_HIDDEN; j++) {
            grad_weights_o[k][j] = delta_o[k] * a_h[j];
        }
    }

    // Hidden Layer Gradients (using selected activation's derivative)
    const delta_h = Array(NUM_HIDDEN).fill(0);
    for (let j = 0; j < NUM_HIDDEN; j++) {
        let error_prop = 0;
        for (let k = 0; k < NUM_OUTPUTS; k++) {
            error_prop += delta_o[k] * weights_o[k][j];
        }
        const activation_derivative = currentActivation.derivative(a_h[j]); // Use selected derivative
        delta_h[j] = error_prop * activation_derivative;
        grad_biases_h[j] = delta_h[j];
        for (let i = 0; i < NUM_INPUTS; i++) {
            grad_weights_h[j][i] = delta_h[j] * inputs[i];
        }
    }

    return { grad_weights_h, grad_biases_h, grad_weights_o, grad_bias_o };
}

function updateWeights(gradients, learningRate) {
    const { grad_weights_h, grad_biases_h, grad_weights_o, grad_bias_o } = gradients;

    // Update Hidden Layer
    for (let j = 0; j < NUM_HIDDEN; j++) {
        biases_h[j] -= learningRate * grad_biases_h[j];
        for (let i = 0; i < NUM_INPUTS; i++) {
            weights_h[j][i] -= learningRate * grad_weights_h[j][i];
        }
    }

    // Update Output Layer
    for (let k = 0; k < NUM_OUTPUTS; k++) {
        bias_o[k] -= learningRate * grad_bias_o[k];
        for (let j = 0; j < NUM_HIDDEN; j++) {
            weights_o[k][j] -= learningRate * grad_weights_o[k][j];
        }
    }
}


// --- Dataset Generation ---
function formatData(class0, class1) {
    const data = [];
    const labels = [];
    class0.x.forEach((x, i) => { data.push([x, class0.y[i]]); labels.push(0); });
    class1.x.forEach((x, i) => { data.push([x, class1.y[i]]); labels.push(1); });
    return { data, labels }; // data = [[x1, y1], [x2, y2]...], labels = [0, 1, 0...]
}

// Use Box-Muller for better Gaussian random numbers
function gaussianRandom() {
    let u = 0, v = 0;
    while(u === 0) u = Math.random();
    while(v === 0) v = Math.random();
    return Math.sqrt( -2.0 * Math.log( u ) ) * Math.cos( 2.0 * Math.PI * v );
}

function generateCircles(numPointsPerClass) {
    const class0_raw = { x: [], y: [] }; const class1_raw = { x: [], y: [] };
    const r1 = 1.5, r2 = 4.0, noise = 0.5;
    for (let i = 0; i < numPointsPerClass; i++) {
        const r_c0 = r1 + gaussianRandom() * noise; const angle0 = Math.random() * 2 * Math.PI;
        class0_raw.x.push(r_c0 * Math.cos(angle0)); class0_raw.y.push(r_c0 * Math.sin(angle0));
        const r_c1 = r2 + gaussianRandom() * noise; const angle1 = Math.random() * 2 * Math.PI;
        class1_raw.x.push(r_c1 * Math.cos(angle1)); class1_raw.y.push(r_c1 * Math.sin(angle1));
    }
    rawData = { class0: class0_raw, class1: class1_raw };
    return formatData(class0_raw, class1_raw);
}

function generateXOR(numPointsPerClass) {
    const class0_raw = { x: [], y: [] }; // Blue dots (TR, BL)
    const class1_raw = { x: [], y: [] }; // Red dots (TL, BR)
    const stdDev = 1.5; // Controls spread within quadrant
    const offset = 1.0; // Minimum distance from origin axis

    for (let i = 0; i < numPointsPerClass; i++) {
        // --- Generate one point for Class 0 (Blue: TR or BL) ---
        const mag_x0 = Math.abs(gaussianRandom() * stdDev) + offset;
        const mag_y0 = Math.abs(gaussianRandom() * stdDev) + offset;
        if (Math.random() < 0.5) { // Top-Right Quadrant
            class0_raw.x.push(mag_x0);
            class0_raw.y.push(mag_y0);
        } else { // Bottom-Left Quadrant
            class0_raw.x.push(-mag_x0);
            class0_raw.y.push(-mag_y0);
        }

        // --- Generate one point for Class 1 (Red: TL or BR) ---
        const mag_x1 = Math.abs(gaussianRandom() * stdDev) + offset;
        const mag_y1 = Math.abs(gaussianRandom() * stdDev) + offset;
         if (Math.random() < 0.5) { // Top-Left Quadrant
            class1_raw.x.push(-mag_x1);
            class1_raw.y.push(mag_y1);
        } else { // Bottom-Right Quadrant
            class1_raw.x.push(mag_x1);
            class1_raw.y.push(-mag_y1);
        }
    }

    rawData = { class0: class0_raw, class1: class1_raw };
    return formatData(class0_raw, class1_raw);
}


function generateMoons(numPointsPerClass) {
    const class0_raw = { x: [], y: [] }; const class1_raw = { x: [], y: [] };
    const n = numPointsPerClass; const noise = 0.15;
    for(let i = 0; i < n; i++) {
        const angle0 = Math.PI * i / n; const x0 = 1.5 * Math.cos(angle0); const y0 = 3.0 * Math.sin(angle0);
        class0_raw.x.push(x0 + (Math.random() - 0.5) * noise * 5); class0_raw.y.push(y0 + (Math.random() - 0.5) * noise * 5);
        const angle1 = Math.PI * (1 + i / n); const x1 = 1.5 * Math.cos(angle1) + 1.0; const y1 = 3.0 * Math.sin(angle1) + 0.5;
        class1_raw.x.push(x1 + (Math.random() - 0.5) * noise * 5); class1_raw.y.push(y1 + (Math.random() - 0.5) * noise * 5);
    }
    rawData = { class0: class0_raw, class1: class1_raw };
    return formatData(class0_raw, class1_raw);
}

function generateLinear(numPointsPerClass) {
    const class0_raw = { x: [], y: [] }; const class1_raw = { x: [], y: [] };
    const slope = 1.5; const intercept = -1; const margin = 1.5; const noise = 0.5;
    for (let i = 0; i < numPointsPerClass; i++) {
        const x0 = (Math.random() - 0.5) * 10; const y0 = slope * x0 + intercept - margin - Math.random() * 3 * noise;
        class0_raw.x.push(x0 + gaussianRandom() * noise); class0_raw.y.push(y0 + gaussianRandom() * noise);
        const x1 = (Math.random() - 0.5) * 10; const y1 = slope * x1 + intercept + margin + Math.random() * 3 * noise;
        class1_raw.x.push(x1 + gaussianRandom() * noise); class1_raw.y.push(y1 + gaussianRandom() * noise);
    }
     rawData = { class0: class0_raw, class1: class1_raw };
    return formatData(class0_raw, class1_raw);
}

function generateSpiral(numPointsPerClass, noise = 0.2) {
    const class0_raw = { x: [], y: [] };
    const class1_raw = { x: [], y: [] };
    const n = numPointsPerClass;

    for (let i = 0; i < n; i++) {
        const r0 = i / n * 5; // Radius
        const t0 = 1.75 * i / n * 2 * Math.PI; // Angle with noise
        const x0 = r0 * Math.sin(t0) + gaussianRandom() * noise;
        const y0 = r0 * Math.cos(t0) + gaussianRandom() * noise;
        class0_raw.x.push(x0);
        class0_raw.y.push(y0);

        const r1 = i / n * 5;
        const t1 = 1.75 * i / n * 2 * Math.PI + Math.PI; // Angle + 180 deg + noise
        const x1 = r1 * Math.sin(t1) + gaussianRandom() * noise;
        const y1 = r1 * Math.cos(t1) + gaussianRandom() * noise;
        class1_raw.x.push(x1);
        class1_raw.y.push(y1);
    }
    rawData = { class0: class0_raw, class1: class1_raw };
    return formatData(class0_raw, class1_raw);
}

function generateGaussians(numPointsPerClass, stdDev = 0.8) {
    const class0_raw = { x: [], y: [] };
    const class1_raw = { x: [], y: [] };
    const center0 = [-2.5, -2.5];
    const center1 = [2.5, 2.5];

    for (let i = 0; i < numPointsPerClass; i++) {
        class0_raw.x.push(center0[0] + gaussianRandom() * stdDev);
        class0_raw.y.push(center0[1] + gaussianRandom() * stdDev);
        class1_raw.x.push(center1[0] + gaussianRandom() * stdDev);
        class1_raw.y.push(center1[1] + gaussianRandom() * stdDev);
    }
    rawData = { class0: class0_raw, class1: class1_raw };
    return formatData(class0_raw, class1_raw);
}

function generateSelectedDataset() {
    stopTraining();
    const numPoints = parseInt(numPointsSlider.value);
    const datasetType = datasetSelect.value;
    numPointsValue.textContent = numPoints;

    switch (datasetType) {
        case 'circles': dataset = generateCircles(numPoints); break;
        case 'xor': dataset = generateXOR(numPoints); break;
        case 'moons': dataset = generateMoons(numPoints); break;
        case 'linear': dataset = generateLinear(numPoints); break;
        case 'spiral': dataset = generateSpiral(numPoints); break;
        case 'gaussians': dataset = generateGaussians(numPoints); break;
        default: dataset = generateCircles(numPoints);
    }
    console.log(`Generated ${datasetType} dataset with ${numPoints} points per class.`);
    plotDataAndBoundary(); // Update plot with new data
    plotLoss(); // Clear loss plot
}

// --- Plotting ---
let nodeElementsSVG = { inputs: [], hidden: [], output: [] };
let weightElementsSVG = { h_weights: [], o_weights: [] }; // Only text elements needed

function createNetworkSVG() {
    networkSvg.innerHTML = ''; // Clear previous
    const width = networkSvg.clientWidth;
    const height = networkSvg.clientHeight;
    const layerX = [width * 0.15, width * 0.5, width * 0.85];
    const nodeRadius = 20;
    const selectedActivationName = activationSelect.options[activationSelect.selectedIndex].text;

    nodeElementsSVG = { inputs: [], hidden: [], output: [] };
    weightElementsSVG = { h_weights: Array(NUM_HIDDEN).fill(0).map(() => []), o_weights: [] };

    // Layer Labels - Updated to show selected activation
    ['Input', `Hidden (${selectedActivationName})`, 'Output (Sigmoid)'].forEach((label, i) => {
        const text = document.createElementNS(svgNS, 'text');
        text.setAttribute('x', layerX[i]); text.setAttribute('y', height * 0.1);
        text.setAttribute('class', 'layer-label'); text.textContent = label;
        networkSvg.appendChild(text);
    });

    const createNodeSVG = (cx, cy, id, label, cssClass, layerArray) => {
        const group = document.createElementNS(svgNS, 'g');
        const circle = document.createElementNS(svgNS, 'circle');
        circle.setAttribute('cx', cx); circle.setAttribute('cy', cy); circle.setAttribute('r', nodeRadius);
        circle.setAttribute('class', `neuron-circle ${cssClass}`);
        const text = document.createElementNS(svgNS, 'text');
        text.setAttribute('x', cx); text.setAttribute('y', cy);
        text.setAttribute('class', 'neuron-text'); text.setAttribute('id', `${id}-text`);
        text.textContent = label;
        group.appendChild(circle); group.appendChild(text); networkSvg.appendChild(group);
        layerArray.push({ group, circle, text, cx, cy });
    };

    // Nodes
    const inputYStep = height / 3;
    for (let i = 0; i < NUM_INPUTS; i++) createNodeSVG(layerX[0], height * 0.3 + i * inputYStep, `input-${i}`, `x${i+1}`, 'input-node-circle', nodeElementsSVG.inputs);
    const hiddenYStep = height / (NUM_HIDDEN + 1);
    for (let i = 0; i < NUM_HIDDEN; i++) createNodeSVG(layerX[1], height * 0.15 + (i+1) * hiddenYStep, `hidden-${i}`, `h${i+1}`, 'hidden-node-circle', nodeElementsSVG.hidden);
    createNodeSVG(layerX[2], height * 0.5, `output-0`, 'y', 'output-node-circle', nodeElementsSVG.output);

    // Lines and Weight Text
    const createLineSVG = (x1, y1, x2, y2, weight, weightArray) => {
        const line = document.createElementNS(svgNS, 'line');
        line.setAttribute('x1', x1); line.setAttribute('y1', y1); line.setAttribute('x2', x2); line.setAttribute('y2', y2);
        line.setAttribute('class', 'connection-line');
        networkSvg.insertBefore(line, networkSvg.firstChild);

        const weightText = document.createElementNS(svgNS, 'text');
        weightText.setAttribute('x', (x1 + x2) / 2); weightText.setAttribute('y', (y1 + y2) / 2 - 3);
        weightText.setAttribute('class', 'weight-text');
        weightText.textContent = weight !== undefined ? weight.toFixed(1) : '?'; // Initial display
        networkSvg.appendChild(weightText);
        if (Array.isArray(weightArray)) { // Check if it's an array before pushing
             weightArray.push(weightText); // Store text element
        }
       
    };

    // Input -> Hidden
    nodeElementsSVG.inputs.forEach((inputNode, i) => {
        nodeElementsSVG.hidden.forEach((hiddenNode, j) => {
            createLineSVG(inputNode.cx, inputNode.cy, hiddenNode.cx, hiddenNode.cy, weights_h ? weights_h[j][i] : undefined, weightElementsSVG.h_weights[j]);
        });
    });
    // Hidden -> Output
    nodeElementsSVG.hidden.forEach((hiddenNode, j) => {
        nodeElementsSVG.output.forEach((outputNode, k) => { // Only k=0 here
             createLineSVG(hiddenNode.cx, hiddenNode.cy, outputNode.cx, outputNode.cy, weights_o ? weights_o[k][j] : undefined, weightElementsSVG.o_weights);
        });
    });
}

function updateNetworkWeightsSVG() {
    if (!weights_h || !weights_o) return; // Not initialized yet

    // Input -> Hidden Weights
    for (let j = 0; j < NUM_HIDDEN; j++) {
        for (let i = 0; i < NUM_INPUTS; i++) {
            if (weightElementsSVG.h_weights[j] && weightElementsSVG.h_weights[j][i]) {
                weightElementsSVG.h_weights[j][i].textContent = weights_h[j][i].toFixed(1);
            }
        }
    }
     // Hidden -> Output Weights
    for (let k = 0; k < NUM_OUTPUTS; k++) { // k=0 only
         for (let j = 0; j < NUM_HIDDEN; j++) {
             if (weightElementsSVG.o_weights[j]) { // Index matches hidden node j
                weightElementsSVG.o_weights[j].textContent = weights_o[k][j].toFixed(1);
            }
         }
    }
}


function calculateDecisionBoundary(resolution = 40) {
    const x_coords = [];
    const y_coords = [];
    const z_values = []; // Predicted output (0 to 1)

    const step = (PLOT_RANGE[1] - PLOT_RANGE[0]) / resolution;

    for (let i = 0; i <= resolution; i++) {
        x_coords.push(PLOT_RANGE[0] + i * step);
        y_coords.push(PLOT_RANGE[0] + i * step);
    }

    for (let j = 0; j <= resolution; j++) {
        const row = [];
        const y = y_coords[j];
        for (let i = 0; i <= resolution; i++) {
            const x = x_coords[i];
            const { a_o } = forwardPass([x, y]);
            row.push(a_o[0]); // Get the prediction
        }
        z_values.push(row);
    }
    return { x: x_coords, y: y_coords, z: z_values };
}


function plotDataAndBoundary() {
    const traceClass0 = {
        x: rawData.class0.x, y: rawData.class0.y, mode: 'markers',
        marker: { color: 'blue', size: 8, symbol: 'circle' }, name: 'Class 0'
    };
    const traceClass1 = {
        x: rawData.class1.x, y: rawData.class1.y, mode: 'markers',
        marker: { color: 'red', size: 8, symbol: 'square' }, name: 'Class 1'
    };

    const traces = [traceClass0, traceClass1];

    if (weights_h) { // Only plot boundary if network is initialized
         const boundaryData = calculateDecisionBoundary();
         const contourTrace = {
            x: boundaryData.x, y: boundaryData.y, z: boundaryData.z,
            type: 'contour',
            colorscale: 'Bluered', // Blue for 0, Red for 1
            contours: {
                coloring: 'heatmap',
                start: 0, end: 1, size: 0.1, // Color steps
                showlines: false // Smoother look
            },
            zmin: 0, zmax: 1, // Fix color scale
            opacity: 0.7,
            name: 'Prediction',
            hoverinfo: 'skip'
         };
         const decisionLine = {
             x: boundaryData.x, y: boundaryData.y, z: boundaryData.z,
             type: 'contour',
             colorscale: [[0, 'black'], [1, 'black']], // Single black line
             contours: {
                 coloring: 'lines',
                 start: 0.5, end: 0.5, size: 0, // Only show line at 0.5
                 showlabels: false
             },
             line: { width: 2 },
             opacity: 1.0,
             hoverinfo: 'skip',
             name: 'Boundary (y=0.5)'
         };

        traces.unshift(contourTrace, decisionLine); // Add boundary behind data
    }


    const layout = {
        title: 'Dataset and Decision Boundary',
        xaxis: { title: 'X1', range: PLOT_RANGE, scaleanchor: "y", scaleratio: 1 },
        yaxis: { title: 'X2', range: PLOT_RANGE },
        margin: { l: 50, r: 30, b: 50, t: 50, pad: 4 },
        legend: { x: 1.05, y: 1 },
        hovermode: 'closest'
    };

    Plotly.react(decisionBoundaryPlotDiv, traces, layout);
}

function plotLoss() {
    const trace = {
        y: lossHistory,
        mode: 'lines',
        name: 'Loss (MSE)'
    };
    const layout = {
        title: 'Training Loss',
        xaxis: { title: 'Training Step' },
        yaxis: { title: 'Loss', type: 'log', autorange: true }, // Log scale often useful
        margin: { l: 50, r: 30, b: 50, t: 50, pad: 4 }
    };
    Plotly.react(lossPlotDiv, [trace], layout);
}


// --- Training Loop ---
function trainStep() {
    if (!dataset || dataset.data.length === 0) return 0;

    // Stochastic Gradient Descent: Pick one random point
    const index = Math.floor(Math.random() * dataset.data.length);
    const inputs = dataset.data[index];
    const target = dataset.labels[index];

    // Forward pass
    const forwardResult = forwardPass(inputs);
    const prediction = forwardResult.a_o[0];

    // Calculate loss
    const loss = mseLoss(target, prediction);

    // Backward pass (get gradients)
    const gradients = backpropagation(inputs, target, forwardResult);

    // Update weights
    const learningRate = Math.pow(10, parseFloat(lrSlider.value));
    updateWeights(gradients, learningRate);

    return loss;
}

function runTraining() {
    if (!isTraining) return;

    const stepsPerFrame = parseInt(updateSpeedSlider.value);
    let currentFrameLossSum = 0;

    for (let i = 0; i < stepsPerFrame; i++) {
        currentFrameLossSum += trainStep();
        stepCount++;
    }

    const averageLoss = currentFrameLossSum / stepsPerFrame;
    if (stepCount % 10 === 0) { // Add loss less frequently to avoid huge arrays
        lossHistory.push(averageLoss);
    }


    // Update plots periodically (not every single step)
    if (stepCount % 50 < stepsPerFrame) { // Ensure update happens at least every 50 steps
        updateNetworkWeightsSVG();
        plotDataAndBoundary();
        plotLoss();
        statusDiv.textContent = `Training... Step: ${stepCount}, Avg Loss: ${averageLoss.toExponential(3)}`;
    }

    animationFrameId = requestAnimationFrame(runTraining);
}

function startTraining() {
    if (isTraining) return;
    isTraining = true;
    startBtn.disabled = true;
    stopBtn.disabled = false;
    stepBtn.disabled = true;
    resetWeightsBtn.disabled = true;
    generateDataBtn.disabled = true;
    datasetSelect.disabled = true;
    numPointsSlider.disabled = true;
    statusDiv.textContent = 'Training...';
    runTraining();
}

function stopTraining() {
    if (!isTraining) return;
    isTraining = false;
    cancelAnimationFrame(animationFrameId);
    animationFrameId = null;
    startBtn.disabled = false;
    stopBtn.disabled = true;
    stepBtn.disabled = false;
    resetWeightsBtn.disabled = false;
    generateDataBtn.disabled = false;
    datasetSelect.disabled = false;
    numPointsSlider.disabled = false;
    statusDiv.textContent = `Status: Stopped at step ${stepCount}. Final Avg Loss: ${lossHistory.length > 0 ? lossHistory[lossHistory.length-1].toExponential(3) : 'N/A'}`;
    // Final update after stopping
    plotDataAndBoundary();
    plotLoss();
}

function doSingleStep() {
    if (isTraining) return;
    const loss = trainStep();
    stepCount++;
     lossHistory.push(loss);
    updateNetworkWeightsSVG();
    plotDataAndBoundary();
    plotLoss();
    statusDiv.textContent = `Status: Stepped (${stepCount}). Loss: ${loss.toExponential(3)}`;
}

function resetNetworkAndData() {
    stopTraining();
    initializeWeights();
    generateSelectedDataset(); // Regenerates data and plots initial state
    createNetworkSVG(); // Recreate SVG with correct label and initial weights
    updateNetworkWeightsSVG();
    statusDiv.textContent = 'Status: Ready (Weights Reset & New Data)';
}


// --- Event Listeners ---
numPointsSlider.addEventListener('input', () => {
    numPointsValue.textContent = numPointsSlider.value;
    // Data will regenerate only when "Generate New Data" is clicked
});
datasetSelect.addEventListener('change', generateSelectedDataset);
lrSlider.addEventListener('input', () => {
    lrValue.textContent = parseFloat(lrSlider.value).toFixed(1);
});
updateSpeedSlider.addEventListener('input', () => {
    updateSpeedValue.textContent = updateSpeedSlider.value;
});
activationSelect.addEventListener('change', () => {
    currentActivation = activations[activationSelect.value];
    console.log(`Hidden activation changed to: ${activationSelect.value}`);
    resetNetworkAndData(); // Reset weights and data when activation changes
});

startBtn.addEventListener('click', startTraining);
stopBtn.addEventListener('click', stopTraining);
stepBtn.addEventListener('click', doSingleStep);
resetWeightsBtn.addEventListener('click', resetNetworkAndData);
generateDataBtn.addEventListener('click', generateSelectedDataset);


// --- Initial Setup ---
document.addEventListener('DOMContentLoaded', () => {
    console.log("Neural Network Demo Part 3 Initializing...");
    currentActivation = activations[activationSelect.value]; // Set initial activation
    initializeWeights();
    generateSelectedDataset(); // Generate initial dataset and plot
    createNetworkSVG();      // Create the SVG structure
    updateNetworkWeightsSVG(); // Display initial weights
    plotLoss(); // Initial empty loss plot
    lrValue.textContent = parseFloat(lrSlider.value).toFixed(1); // Set initial display
    updateSpeedValue.textContent = updateSpeedSlider.value; // Set initial display
    numPointsValue.textContent = numPointsSlider.value; // Set initial display

    console.log("Initialization complete.");
});

</script>

</body>
</html> 